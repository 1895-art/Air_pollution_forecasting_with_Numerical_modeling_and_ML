{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting air pollution with RNNs\n",
    "### result    \n",
    "1. Simple RNN\n",
    "2. Simple LSTM\n",
    "3. Stacked LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.zeros((314,1))\n",
    "\n",
    "for hour in range(24) :\n",
    "    path = os.path.join(os.getcwd(), 'air_pollution_data', 'Hour_{}'.format(hour+1) + '.csv')\n",
    "    csv = pd.read_csv(path, encoding = 'cp949', header = None)\n",
    "    csv.head()\n",
    "    data = csv.values[:,-1]\n",
    "    data = data.reshape(314,1)\n",
    "    \n",
    "    dataset = np.concatenate((dataset, data), axis = 1)\n",
    "    \n",
    "dataset = dataset[:, 1:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.reshape(314,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normalize the dataset\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaled_data = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset : (314, 1, 24)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.reshape(314,1,24)\n",
    "print(\"Shape of dataset :\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[:, :, :23]\n",
    "y = dataset[:, :, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x : (314, 1, 23)\n",
      "Shape of y : (314, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of x :\", x.shape)\n",
    "print(\"Shape of y :\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 1, 23) (251, 1)\n",
      "(62, 1, 23) (62, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x[:251,:,:]\n",
    "y_train = y[:251,:]\n",
    "\n",
    "x_test = x[252:,:,:]\n",
    "y_test = y[252:,:]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn = Sequential()\n",
    "simple_rnn.add(SimpleRNN(16, input_shape=(1,23)))\n",
    "simple_rnn.add(Dense(1))\n",
    "simple_rnn.compile(loss='mae', optimizer=RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "    \n",
    "losses = tf.compat.v1.losses.log_loss\n",
    "simple_rnn.compile(loss = root_mean_squared_error, optimizer='adam')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 51 samples\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 70.5200 - val_loss: 77.0214\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 65.8499 - val_loss: 72.9061\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 62.2454 - val_loss: 69.6286\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 59.2304 - val_loss: 66.5276\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 56.7415 - val_loss: 63.6868\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 54.6213 - val_loss: 61.1090\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 52.4296 - val_loss: 58.4576\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 50.2999 - val_loss: 55.8413\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 48.3397 - val_loss: 53.2039\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 46.3456 - val_loss: 50.6520\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 44.3129 - val_loss: 48.1765\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 42.3444 - val_loss: 45.7063\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 40.3337 - val_loss: 43.3775\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 38.3903 - val_loss: 41.1571\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 36.4431 - val_loss: 39.0993\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 34.4985 - val_loss: 37.1472\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 32.5515 - val_loss: 35.2734\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 30.6725 - val_loss: 33.7141\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 28.9856 - val_loss: 32.2425\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 27.4713 - val_loss: 30.9855\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 26.0988 - val_loss: 29.8674\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 24.8663 - val_loss: 28.8914\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 23.7190 - val_loss: 28.0263\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 22.6418 - val_loss: 27.1768\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 21.7024 - val_loss: 26.5564\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 20.9770 - val_loss: 26.0354\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 20.4421 - val_loss: 25.6986\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 20.0628 - val_loss: 25.4131\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.8049 - val_loss: 25.2113\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.6064 - val_loss: 25.0506\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.4641 - val_loss: 24.8749\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.3900 - val_loss: 24.7809\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.3400 - val_loss: 24.6920\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.3027 - val_loss: 24.6368\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.2809 - val_loss: 24.6159\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.2691 - val_loss: 24.5984\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.2483 - val_loss: 24.5720\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.2414 - val_loss: 24.5495\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.2227 - val_loss: 24.5312\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.2106 - val_loss: 24.5088\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.1948 - val_loss: 24.5019\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.1851 - val_loss: 24.4957\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.1650 - val_loss: 24.4635\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.1528 - val_loss: 24.4496\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.1432 - val_loss: 24.4467\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.1286 - val_loss: 24.4452\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.1176 - val_loss: 24.4268\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.1068 - val_loss: 24.4411\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.0962 - val_loss: 24.4468\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.0816 - val_loss: 24.4349\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.1063 - val_loss: 24.4381\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.0580 - val_loss: 24.4262\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.0477 - val_loss: 24.4158\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.0366 - val_loss: 24.4325\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.0214 - val_loss: 24.4227\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.0123 - val_loss: 24.4365\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.9987 - val_loss: 24.4186\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.9890 - val_loss: 24.4194\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.9763 - val_loss: 24.4260\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.9680 - val_loss: 24.4100\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.9526 - val_loss: 24.4299\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.9407 - val_loss: 24.4269\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.9311 - val_loss: 24.4378\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.9167 - val_loss: 24.4288\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.9042 - val_loss: 24.4236\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.8941 - val_loss: 24.4228\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.8857 - val_loss: 24.4341\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.8704 - val_loss: 24.4196\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.8587 - val_loss: 24.4361\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.8458 - val_loss: 24.4189\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.8365 - val_loss: 24.4184\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.8230 - val_loss: 24.4108\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.8112 - val_loss: 24.4153\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.7983 - val_loss: 24.4291\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.7915 - val_loss: 24.4328\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.7793 - val_loss: 24.4297\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.7647 - val_loss: 24.4298\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.7551 - val_loss: 24.4362\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.7417 - val_loss: 24.4306\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.7313 - val_loss: 24.4402\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.7195 - val_loss: 24.4180\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.6377 - val_loss: 24.4091\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.7544 - val_loss: 24.3819\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.7059 - val_loss: 24.3868\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.6766 - val_loss: 24.4120\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.1376 - val_loss: 24.9486\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 17.7540 - val_loss: 24.7965\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 17.1094 - val_loss: 24.5441\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.9378 - val_loss: 24.2283\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.9236 - val_loss: 24.5806\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.8009 - val_loss: 24.1449\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.7097 - val_loss: 24.4023\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.8564 - val_loss: 24.1248\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.7287 - val_loss: 24.4397\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.5663 - val_loss: 24.0554\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.6316 - val_loss: 23.9827\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.5438 - val_loss: 24.1340\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.3355 - val_loss: 23.7277\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.3875 - val_loss: 23.4922\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.1962 - val_loss: 23.6379\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_hist = simple_rnn.fit(x_train, y_train,\n",
    "                       epochs = 100,\n",
    "                       batch_size = 1,\n",
    "                       verbose = 1, \n",
    "                       validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, title):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Nb Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    val_loss = history.history['val_loss']\n",
    "    min_idx = np.argmin(val_loss)\n",
    "    min_val_loss = val_loss[min_idx]\n",
    "    print('Minimum validation loss of {} reached at epoch {}'.format(min_val_loss, min_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss of 23.492153392118567 reached at epoch 98\n"
     ]
    }
   ],
   "source": [
    "plot_loss(simple_rnn_hist, 'SimpleRNN - Train & Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE : 23.23517998710388\n",
      "Test RMSE : 37.71782444725679\n"
     ]
    }
   ],
   "source": [
    "train_pred = simple_rnn.predict(x_train)\n",
    "test_pred = simple_rnn.predict(x_test)\n",
    "\n",
    "train_RMSE = mean_squared_error(y_train, train_pred) ** 0.5\n",
    "test_RMSE = mean_squared_error(y_test, test_pred) ** 0.5\n",
    "\n",
    "print('Train RMSE :', train_RMSE)\n",
    "print('Test RMSE :', test_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of 314 dataset : 26.69200521340075\n"
     ]
    }
   ],
   "source": [
    "yy = simple_rnn.predict(x)\n",
    "result = mean_squared_error(y, yy) ** 0.5\n",
    "print(\"RMSE of 314 dataset :\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model architecture\n",
    "model_json = simple_rnn.to_json()\n",
    "open('simple_rnn_with_100iterations.json', 'w').write(model_json)\n",
    "\n",
    "# save model's learned weights\n",
    "simple_rnn.save_weights('simple_rnn_weights_with_100iterations.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_98 (LSTM)               (None, 16)                2560      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,577\n",
      "Trainable params: 2,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_lstm = Sequential()\n",
    "simple_lstm.add(LSTM(16, input_shape=(1, 23)))\n",
    "simple_lstm.add(Dense(1))\n",
    "simple_lstm.compile(loss='mae', optimizer=RMSprop())\n",
    "simple_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 51 samples\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 70.1325 - val_loss: 78.4084\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 68.6292 - val_loss: 77.0527\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 67.3144 - val_loss: 75.8008\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 65.9646 - val_loss: 74.4792\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 64.4322 - val_loss: 72.6344\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 62.8594 - val_loss: 71.2313\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 61.5452 - val_loss: 69.8840\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 60.2941 - val_loss: 68.5651\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 59.1479 - val_loss: 67.3315\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 58.1002 - val_loss: 66.1258\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 57.0772 - val_loss: 64.9463\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 56.0871 - val_loss: 63.7761\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 55.0841 - val_loss: 62.6117\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 54.1479 - val_loss: 61.4828\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 53.2519 - val_loss: 60.3550\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 52.3665 - val_loss: 59.2515\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 51.3580 - val_loss: 57.7971\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 50.2647 - val_loss: 56.5656\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 49.3036 - val_loss: 55.3256\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 48.3355 - val_loss: 54.1083\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 47.3561 - val_loss: 52.9469\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 46.3779 - val_loss: 51.6497\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 45.3748 - val_loss: 50.4628\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 44.4817 - val_loss: 49.5890\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 43.1850 - val_loss: 48.0252\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 41.8869 - val_loss: 46.4401\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 40.6272 - val_loss: 45.1657\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 39.5039 - val_loss: 43.9715\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 38.3154 - val_loss: 42.6713\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 37.1425 - val_loss: 41.4781\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 35.9331 - val_loss: 40.3619\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 34.8806 - val_loss: 39.1514\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 33.7205 - val_loss: 38.0875\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 32.5373 - val_loss: 37.1871\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 31.3994 - val_loss: 36.1796\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 30.1829 - val_loss: 35.0903\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 29.1119 - val_loss: 34.3451\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 28.1173 - val_loss: 33.3713\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 27.1600 - val_loss: 32.6213\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 26.1904 - val_loss: 31.8813\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 25.3976 - val_loss: 31.1784\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 24.4349 - val_loss: 30.5300\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 23.6382 - val_loss: 29.9129\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 22.8798 - val_loss: 29.4841\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 22.2219 - val_loss: 28.7398\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 21.5377 - val_loss: 28.4369\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 20.7956 - val_loss: 27.9041\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 20.1165 - val_loss: 27.4267\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 19.3615 - val_loss: 27.0236\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.8855 - val_loss: 26.6696\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 18.3131 - val_loss: 26.2200\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 17.9671 - val_loss: 26.0860\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 17.5565 - val_loss: 25.7327\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 17.1394 - val_loss: 25.7080\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.9628 - val_loss: 25.4481\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.7055 - val_loss: 25.3546\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.5820 - val_loss: 25.2181\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.3734 - val_loss: 25.1355\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.0699 - val_loss: 24.8654\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 16.0986 - val_loss: 24.7797\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.9545 - val_loss: 24.8265\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.7649 - val_loss: 24.6327\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.8167 - val_loss: 24.7513\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.7947 - val_loss: 24.4196\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.6381 - val_loss: 24.4566\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.8328 - val_loss: 24.6359\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.5409 - val_loss: 24.3654\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 15.6850 - val_loss: 24.3016\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.6073 - val_loss: 24.2983\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.6994 - val_loss: 23.8792\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.8032 - val_loss: 24.4308\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.4094 - val_loss: 23.4339\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.5949 - val_loss: 24.0247\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.2770 - val_loss: 24.2549\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.3844 - val_loss: 23.9226\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.0945 - val_loss: 23.3361\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.0387 - val_loss: 23.5624\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.3474 - val_loss: 23.9036\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.1918 - val_loss: 23.9844\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.9667 - val_loss: 23.1847\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.2679 - val_loss: 23.8310\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.0070 - val_loss: 23.9069\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.0092 - val_loss: 24.0074\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.9930 - val_loss: 23.6904\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.9476 - val_loss: 23.8784\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 15.1084 - val_loss: 23.1995\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.7699 - val_loss: 23.4659\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.6579 - val_loss: 23.0784\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.5347 - val_loss: 23.6578\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.5916 - val_loss: 23.5500\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.6342 - val_loss: 22.9421\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.5499 - val_loss: 23.5819\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.5219 - val_loss: 23.6907\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.4923 - val_loss: 23.7021\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.4801 - val_loss: 23.9076\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.0992 - val_loss: 23.8725\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.1515 - val_loss: 23.3184\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 13.9551 - val_loss: 23.5939\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.1901 - val_loss: 23.8009\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 14.0737 - val_loss: 23.7614\n"
     ]
    }
   ],
   "source": [
    "simple_lstm_hist = simple_lstm.fit(x_train, y_train,\n",
    "                       epochs = 100,\n",
    "                       batch_size = 1,\n",
    "                       verbose = 1, \n",
    "                       validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss of 22.942065295051126 reached at epoch 90\n"
     ]
    }
   ],
   "source": [
    "plot_loss(simple_lstm_hist, 'Simple LSTM - Train & Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE : 21.2162573860298\n",
      "Test RMSE : 38.52582741978493\n"
     ]
    }
   ],
   "source": [
    "train_pred = simple_lstm.predict(x_train)\n",
    "test_pred = simple_lstm.predict(x_test)\n",
    "\n",
    "train_RMSE = mean_squared_error(y_train, train_pred) ** 0.5\n",
    "test_RMSE = mean_squared_error(y_test, test_pred) ** 0.5\n",
    "\n",
    "print('Train RMSE :', train_RMSE)\n",
    "print('Test RMSE :', test_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of 314 dataset : 25.551617402133502\n"
     ]
    }
   ],
   "source": [
    "yy = simple_lstm.predict(x)\n",
    "result = mean_squared_error(y, yy) ** 0.5\n",
    "print(\"RMSE of 314 dataset :\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model architecture\n",
    "model_json = simple_lstm.to_json()\n",
    "open('simple_lstm_with_100iterations.json', 'w').write(model_json)\n",
    "\n",
    "# save model's learned weights\n",
    "simple_lstm.save_weights('simple_lstm_weights_with_100iterations.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. Stacked LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_108 (LSTM)              (None, 1, 256)            286720    \n",
      "_________________________________________________________________\n",
      "lstm_109 (LSTM)              (None, 1, 256)            525312    \n",
      "_________________________________________________________________\n",
      "lstm_110 (LSTM)              (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,345,601\n",
      "Trainable params: 1,345,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stacked_lstm = Sequential()\n",
    "stacked_lstm.add(LSTM(256, input_shape=(1, 23), return_sequences=True))\n",
    "# stacked_lstm.add(Dropout(0.3))\n",
    "\n",
    "stacked_lstm.add(LSTM(256, return_sequences=True))\n",
    "# stacked_lstm.add(Dropout(0.3))\n",
    "\n",
    "stacked_lstm.add(LSTM(256))\n",
    "# stacked_lstm.add(Dropout(0.3))\n",
    "\n",
    "stacked_lstm.add(Dense(32, activation = \"relu\"))\n",
    "\n",
    "stacked_lstm.add(Dense(1))\n",
    "stacked_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = tf.compat.v1.losses.log_loss\n",
    "stacked_lstm.compile(loss = root_mean_squared_error, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 51 samples\n",
      "Epoch 1/1000\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 76.9983 - val_loss: 85.1208\n",
      "Epoch 2/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 76.9387 - val_loss: 85.0522\n",
      "Epoch 3/1000\n",
      "200/200 [==============================] - 0s 323us/step - loss: 76.8684 - val_loss: 84.9526\n",
      "Epoch 4/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 76.7678 - val_loss: 84.8055\n",
      "Epoch 5/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 76.6223 - val_loss: 84.5951\n",
      "Epoch 6/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 76.4166 - val_loss: 84.3014\n",
      "Epoch 7/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 76.1325 - val_loss: 83.9003\n",
      "Epoch 8/1000\n",
      "200/200 [==============================] - 0s 393us/step - loss: 75.7487 - val_loss: 83.3676\n",
      "Epoch 9/1000\n",
      "200/200 [==============================] - 0s 495us/step - loss: 75.2415 - val_loss: 82.6838\n",
      "Epoch 10/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 74.5845 - val_loss: 81.8264\n",
      "Epoch 11/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 73.7602 - val_loss: 80.7991\n",
      "Epoch 12/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 72.7669 - val_loss: 79.6123\n",
      "Epoch 13/1000\n",
      "200/200 [==============================] - 0s 375us/step - loss: 71.6138 - val_loss: 78.2937\n",
      "Epoch 14/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 70.3246 - val_loss: 76.8709\n",
      "Epoch 15/1000\n",
      "200/200 [==============================] - 0s 373us/step - loss: 68.9285 - val_loss: 75.3743\n",
      "Epoch 16/1000\n",
      "200/200 [==============================] - 0s 390us/step - loss: 67.4555 - val_loss: 73.8239\n",
      "Epoch 17/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 65.9316 - val_loss: 72.2441\n",
      "Epoch 18/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 64.3892 - val_loss: 70.6639\n",
      "Epoch 19/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 62.8553 - val_loss: 69.1022\n",
      "Epoch 20/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 61.3457 - val_loss: 67.5743\n",
      "Epoch 21/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 59.8723 - val_loss: 66.0864\n",
      "Epoch 22/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 58.4462 - val_loss: 64.6479\n",
      "Epoch 23/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 57.0732 - val_loss: 63.2684\n",
      "Epoch 24/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 55.7568 - val_loss: 61.9511\n",
      "Epoch 25/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 54.4995 - val_loss: 60.6911\n",
      "Epoch 26/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 53.2998 - val_loss: 59.4809\n",
      "Epoch 27/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 52.1531 - val_loss: 58.3115\n",
      "Epoch 28/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 51.0515 - val_loss: 57.1757\n",
      "Epoch 29/1000\n",
      "200/200 [==============================] - 0s 300us/step - loss: 49.9866 - val_loss: 56.0679\n",
      "Epoch 30/1000\n",
      "200/200 [==============================] - 0s 305us/step - loss: 48.9519 - val_loss: 54.9827\n",
      "Epoch 31/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 47.9430 - val_loss: 53.9158\n",
      "Epoch 32/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 46.9566 - val_loss: 52.8642\n",
      "Epoch 33/1000\n",
      "200/200 [==============================] - 0s 400us/step - loss: 45.9897 - val_loss: 51.8255\n",
      "Epoch 34/1000\n",
      "200/200 [==============================] - 0s 415us/step - loss: 45.0404 - val_loss: 50.7978\n",
      "Epoch 35/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 44.1072 - val_loss: 49.7808\n",
      "Epoch 36/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 43.1903 - val_loss: 48.7714\n",
      "Epoch 37/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 42.2871 - val_loss: 47.7717\n",
      "Epoch 38/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 41.4002 - val_loss: 46.7803\n",
      "Epoch 39/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 40.5290 - val_loss: 45.7976\n",
      "Epoch 40/1000\n",
      "200/200 [==============================] - 0s 353us/step - loss: 39.6742 - val_loss: 44.8243\n",
      "Epoch 41/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 38.8372 - val_loss: 43.8613\n",
      "Epoch 42/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 38.0194 - val_loss: 42.9101\n",
      "Epoch 43/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 37.2227 - val_loss: 41.9724\n",
      "Epoch 44/1000\n",
      "200/200 [==============================] - 0s 415us/step - loss: 36.4495 - val_loss: 41.0503\n",
      "Epoch 45/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 35.7023 - val_loss: 40.1461\n",
      "Epoch 46/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 34.9839 - val_loss: 39.2626\n",
      "Epoch 47/1000\n",
      "200/200 [==============================] - 0s 395us/step - loss: 34.2970 - val_loss: 38.4023\n",
      "Epoch 48/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 33.6443 - val_loss: 37.5678\n",
      "Epoch 49/1000\n",
      "200/200 [==============================] - 0s 347us/step - loss: 33.0284 - val_loss: 36.7617\n",
      "Epoch 50/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 32.4518 - val_loss: 35.9866\n",
      "Epoch 51/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 31.9164 - val_loss: 35.2451\n",
      "Epoch 52/1000\n",
      "200/200 [==============================] - 0s 373us/step - loss: 31.4244 - val_loss: 34.5395\n",
      "Epoch 53/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 30.9769 - val_loss: 33.8721\n",
      "Epoch 54/1000\n",
      "200/200 [==============================] - 0s 395us/step - loss: 30.5749 - val_loss: 33.2450\n",
      "Epoch 55/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 30.2189 - val_loss: 32.6597\n",
      "Epoch 56/1000\n",
      "200/200 [==============================] - 0s 375us/step - loss: 29.9088 - val_loss: 32.1172\n",
      "Epoch 57/1000\n",
      "200/200 [==============================] - 0s 390us/step - loss: 29.6436 - val_loss: 31.6186\n",
      "Epoch 58/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 29.4210 - val_loss: 31.1644\n",
      "Epoch 59/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 29.2389 - val_loss: 30.7541\n",
      "Epoch 60/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 29.0952 - val_loss: 30.3869\n",
      "Epoch 61/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 28.9860 - val_loss: 30.0616\n",
      "Epoch 62/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 28.9065 - val_loss: 29.7759\n",
      "Epoch 63/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 28.8522 - val_loss: 29.5279\n",
      "Epoch 64/1000\n",
      "200/200 [==============================] - 0s 405us/step - loss: 28.8195 - val_loss: 29.3148\n",
      "Epoch 65/1000\n",
      "200/200 [==============================] - 0s 390us/step - loss: 28.8042 - val_loss: 29.1335\n",
      "Epoch 66/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 28.8009 - val_loss: 28.9812\n",
      "Epoch 67/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 28.8027 - val_loss: 28.8546\n",
      "Epoch 68/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 28.8022 - val_loss: 28.7509\n",
      "Epoch 69/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 28.7927 - val_loss: 28.6671\n",
      "Epoch 70/1000\n",
      "200/200 [==============================] - 0s 430us/step - loss: 28.7688 - val_loss: 28.6008\n",
      "Epoch 71/1000\n",
      "200/200 [==============================] - 0s 348us/step - loss: 28.7305 - val_loss: 28.5489\n",
      "Epoch 72/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 28.6679 - val_loss: 28.5095\n",
      "Epoch 73/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 28.5574 - val_loss: 28.4816\n",
      "Epoch 74/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 28.3516 - val_loss: 28.4638\n",
      "Epoch 75/1000\n",
      "200/200 [==============================] - 0s 395us/step - loss: 27.9478 - val_loss: 28.4537\n",
      "Epoch 76/1000\n",
      "200/200 [==============================] - 0s 375us/step - loss: 27.1041 - val_loss: 28.4537\n",
      "Epoch 77/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 25.3533 - val_loss: 28.4390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 22.2529 - val_loss: 28.3672\n",
      "Epoch 79/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 19.2675 - val_loss: 28.1834\n",
      "Epoch 80/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 19.6758 - val_loss: 28.0308\n",
      "Epoch 81/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 20.3257 - val_loss: 28.0978\n",
      "Epoch 82/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 20.0792 - val_loss: 28.0561\n",
      "Epoch 83/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 19.3121 - val_loss: 27.9906\n",
      "Epoch 84/1000\n",
      "200/200 [==============================] - 0s 390us/step - loss: 18.6311 - val_loss: 27.9449\n",
      "Epoch 85/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 18.3014 - val_loss: 27.8753\n",
      "Epoch 86/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 18.0159 - val_loss: 27.7240\n",
      "Epoch 87/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 17.6620 - val_loss: 27.5799\n",
      "Epoch 88/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 17.3237 - val_loss: 27.4595\n",
      "Epoch 89/1000\n",
      "200/200 [==============================] - 0s 305us/step - loss: 17.1240 - val_loss: 27.2854\n",
      "Epoch 90/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 16.7686 - val_loss: 27.1641\n",
      "Epoch 91/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 16.4443 - val_loss: 27.1844\n",
      "Epoch 92/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 16.1607 - val_loss: 27.1885\n",
      "Epoch 93/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 15.9042 - val_loss: 27.1040\n",
      "Epoch 94/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 15.6682 - val_loss: 26.9601\n",
      "Epoch 95/1000\n",
      "200/200 [==============================] - 0s 395us/step - loss: 15.4183 - val_loss: 27.0733\n",
      "Epoch 96/1000\n",
      "200/200 [==============================] - 0s 430us/step - loss: 15.2109 - val_loss: 27.0527\n",
      "Epoch 97/1000\n",
      "200/200 [==============================] - 0s 375us/step - loss: 15.0359 - val_loss: 26.9410\n",
      "Epoch 98/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 14.8242 - val_loss: 26.8081\n",
      "Epoch 99/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 14.6300 - val_loss: 26.3068\n",
      "Epoch 100/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 14.4480 - val_loss: 25.8297\n",
      "Epoch 101/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 14.2170 - val_loss: 25.5259\n",
      "Epoch 102/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 13.9986 - val_loss: 25.1383\n",
      "Epoch 103/1000\n",
      "200/200 [==============================] - 0s 375us/step - loss: 13.7348 - val_loss: 24.8069\n",
      "Epoch 104/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 13.4577 - val_loss: 24.5849\n",
      "Epoch 105/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 13.1965 - val_loss: 24.3630\n",
      "Epoch 106/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 12.9623 - val_loss: 24.1478\n",
      "Epoch 107/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 12.7197 - val_loss: 23.8293\n",
      "Epoch 108/1000\n",
      "200/200 [==============================] - 0s 305us/step - loss: 12.4937 - val_loss: 23.4505\n",
      "Epoch 109/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 12.2622 - val_loss: 22.8618\n",
      "Epoch 110/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 12.0520 - val_loss: 22.5074\n",
      "Epoch 111/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 11.8629 - val_loss: 22.0956\n",
      "Epoch 112/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 11.7394 - val_loss: 21.7103\n",
      "Epoch 113/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 11.5285 - val_loss: 21.2541\n",
      "Epoch 114/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 11.3064 - val_loss: 20.9087\n",
      "Epoch 115/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 11.1363 - val_loss: 20.6671\n",
      "Epoch 116/1000\n",
      "200/200 [==============================] - 0s 420us/step - loss: 10.9983 - val_loss: 20.3059\n",
      "Epoch 117/1000\n",
      "200/200 [==============================] - 0s 480us/step - loss: 10.9427 - val_loss: 20.3326\n",
      "Epoch 118/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 11.0149 - val_loss: 20.1221\n",
      "Epoch 119/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 11.1824 - val_loss: 19.9312\n",
      "Epoch 120/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 10.5782 - val_loss: 20.0476\n",
      "Epoch 121/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 10.9343 - val_loss: 19.5770\n",
      "Epoch 122/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 10.9406 - val_loss: 19.0657\n",
      "Epoch 123/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 10.5123 - val_loss: 19.6138\n",
      "Epoch 124/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 11.0127 - val_loss: 19.0641\n",
      "Epoch 125/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 10.3372 - val_loss: 19.3631\n",
      "Epoch 126/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 10.4883 - val_loss: 19.3404\n",
      "Epoch 127/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 10.1594 - val_loss: 19.3602\n",
      "Epoch 128/1000\n",
      "200/200 [==============================] - 0s 338us/step - loss: 10.2290 - val_loss: 18.8109\n",
      "Epoch 129/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 10.1625 - val_loss: 18.7832\n",
      "Epoch 130/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 10.0685 - val_loss: 19.4423\n",
      "Epoch 131/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 10.1207 - val_loss: 18.9080\n",
      "Epoch 132/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 9.8255 - val_loss: 18.8156\n",
      "Epoch 133/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 9.8860 - val_loss: 18.8285\n",
      "Epoch 134/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 9.7566 - val_loss: 18.3879\n",
      "Epoch 135/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 9.5836 - val_loss: 18.0381\n",
      "Epoch 136/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 9.6330 - val_loss: 18.3148\n",
      "Epoch 137/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 9.4596 - val_loss: 18.3557\n",
      "Epoch 138/1000\n",
      "200/200 [==============================] - 0s 305us/step - loss: 9.3750 - val_loss: 18.0643\n",
      "Epoch 139/1000\n",
      "200/200 [==============================] - 0s 305us/step - loss: 9.3463 - val_loss: 18.2085\n",
      "Epoch 140/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 9.1998 - val_loss: 18.0181\n",
      "Epoch 141/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 9.0942 - val_loss: 17.7571\n",
      "Epoch 142/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 9.0094 - val_loss: 18.1139\n",
      "Epoch 143/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 8.9716 - val_loss: 17.6951\n",
      "Epoch 144/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 8.9241 - val_loss: 18.1385\n",
      "Epoch 145/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 8.8067 - val_loss: 17.6231\n",
      "Epoch 146/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 8.6506 - val_loss: 17.9844\n",
      "Epoch 147/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 8.5013 - val_loss: 17.7276\n",
      "Epoch 148/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 8.3207 - val_loss: 18.0021\n",
      "Epoch 149/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 8.2150 - val_loss: 17.6236\n",
      "Epoch 150/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 8.1601 - val_loss: 18.4825\n",
      "Epoch 151/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 8.4107 - val_loss: 17.8939\n",
      "Epoch 152/1000\n",
      "200/200 [==============================] - 0s 410us/step - loss: 9.4243 - val_loss: 18.3407\n",
      "Epoch 153/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 8.0247 - val_loss: 17.8625\n",
      "Epoch 154/1000\n",
      "200/200 [==============================] - 0s 390us/step - loss: 7.5419 - val_loss: 17.2993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/1000\n",
      "200/200 [==============================] - 0s 405us/step - loss: 8.1142 - val_loss: 18.9429\n",
      "Epoch 156/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 8.3118 - val_loss: 17.4265\n",
      "Epoch 157/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 7.9852 - val_loss: 17.8114\n",
      "Epoch 158/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 7.1602 - val_loss: 18.6989\n",
      "Epoch 159/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 7.5434 - val_loss: 17.2201\n",
      "Epoch 160/1000\n",
      "200/200 [==============================] - 0s 375us/step - loss: 8.3147 - val_loss: 17.6636\n",
      "Epoch 161/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 6.9100 - val_loss: 19.1213\n",
      "Epoch 162/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 7.4244 - val_loss: 17.4790\n",
      "Epoch 163/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 8.3860 - val_loss: 17.7921\n",
      "Epoch 164/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 6.5852 - val_loss: 20.1532\n",
      "Epoch 165/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 8.4580 - val_loss: 17.3563\n",
      "Epoch 166/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 8.0686 - val_loss: 17.2840\n",
      "Epoch 167/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 6.9153 - val_loss: 21.5504\n",
      "Epoch 168/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 9.2659 - val_loss: 17.9670\n",
      "Epoch 169/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 6.3241 - val_loss: 17.9364\n",
      "Epoch 170/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 8.1136 - val_loss: 18.0945\n",
      "Epoch 171/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 6.3707 - val_loss: 19.9407\n",
      "Epoch 172/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 7.5186 - val_loss: 17.5736\n",
      "Epoch 173/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 6.7634 - val_loss: 17.5842\n",
      "Epoch 174/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 6.7906 - val_loss: 19.4663\n",
      "Epoch 175/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 6.8374 - val_loss: 18.2662\n",
      "Epoch 176/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 6.0817 - val_loss: 17.9109\n",
      "Epoch 177/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 6.8399 - val_loss: 18.4299\n",
      "Epoch 178/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 5.9455 - val_loss: 19.5256\n",
      "Epoch 179/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 6.4774 - val_loss: 17.8239\n",
      "Epoch 180/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 6.3086 - val_loss: 18.0642\n",
      "Epoch 181/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 5.8392 - val_loss: 19.7810\n",
      "Epoch 182/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 6.5213 - val_loss: 17.8107\n",
      "Epoch 183/1000\n",
      "200/200 [==============================] - 0s 390us/step - loss: 5.9291 - val_loss: 18.0396\n",
      "Epoch 184/1000\n",
      "200/200 [==============================] - 0s 405us/step - loss: 5.7178 - val_loss: 19.6409\n",
      "Epoch 185/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 6.3218 - val_loss: 17.9128\n",
      "Epoch 186/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 5.7544 - val_loss: 17.7675\n",
      "Epoch 187/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 5.4836 - val_loss: 19.0986\n",
      "Epoch 188/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 6.0546 - val_loss: 17.3692\n",
      "Epoch 189/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 5.8832 - val_loss: 18.1671\n",
      "Epoch 190/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 5.3226 - val_loss: 19.2265\n",
      "Epoch 191/1000\n",
      "200/200 [==============================] - 0s 383us/step - loss: 5.8246 - val_loss: 17.5624\n",
      "Epoch 192/1000\n",
      "200/200 [==============================] - 0s 415us/step - loss: 5.9920 - val_loss: 18.1752\n",
      "Epoch 193/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 5.1787 - val_loss: 19.1550\n",
      "Epoch 194/1000\n",
      "200/200 [==============================] - 0s 410us/step - loss: 5.6099 - val_loss: 17.4197\n",
      "Epoch 195/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 6.1356 - val_loss: 18.3941\n",
      "Epoch 196/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 5.0953 - val_loss: 19.1639\n",
      "Epoch 197/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 5.6070 - val_loss: 17.7178\n",
      "Epoch 198/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 6.2260 - val_loss: 18.4615\n",
      "Epoch 199/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 4.9551 - val_loss: 19.9490\n",
      "Epoch 200/1000\n",
      "200/200 [==============================] - 0s 420us/step - loss: 5.7846 - val_loss: 17.6562\n",
      "Epoch 201/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 6.1997 - val_loss: 18.5246\n",
      "Epoch 202/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.8696 - val_loss: 21.0030\n",
      "Epoch 203/1000\n",
      "200/200 [==============================] - 0s 328us/step - loss: 6.5051 - val_loss: 17.9245\n",
      "Epoch 204/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 5.8135 - val_loss: 18.2035\n",
      "Epoch 205/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 5.0678 - val_loss: 20.7371\n",
      "Epoch 206/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 6.7435 - val_loss: 18.1778\n",
      "Epoch 207/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 4.8657 - val_loss: 17.7118\n",
      "Epoch 208/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 5.5791 - val_loss: 19.7302\n",
      "Epoch 209/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 5.4350 - val_loss: 18.5579\n",
      "Epoch 210/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 4.6489 - val_loss: 17.9519\n",
      "Epoch 211/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 5.2794 - val_loss: 19.2392\n",
      "Epoch 212/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.8978 - val_loss: 18.6598\n",
      "Epoch 213/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 4.5449 - val_loss: 18.0523\n",
      "Epoch 214/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 4.9133 - val_loss: 19.5486\n",
      "Epoch 215/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.8378 - val_loss: 18.5469\n",
      "Epoch 216/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.5089 - val_loss: 18.8530\n",
      "Epoch 217/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 4.3841 - val_loss: 19.5065\n",
      "Epoch 218/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 4.5183 - val_loss: 18.3364\n",
      "Epoch 219/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.7190 - val_loss: 19.7311\n",
      "Epoch 220/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.5578 - val_loss: 18.5634\n",
      "Epoch 221/1000\n",
      "200/200 [==============================] - 0s 305us/step - loss: 4.3604 - val_loss: 19.2118\n",
      "Epoch 222/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.2038 - val_loss: 18.8348\n",
      "Epoch 223/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 4.1318 - val_loss: 19.0500\n",
      "Epoch 224/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 4.0687 - val_loss: 18.9211\n",
      "Epoch 225/1000\n",
      "200/200 [==============================] - 0s 430us/step - loss: 4.0194 - val_loss: 19.3708\n",
      "Epoch 226/1000\n",
      "200/200 [==============================] - 0s 435us/step - loss: 4.0159 - val_loss: 18.5770\n",
      "Epoch 227/1000\n",
      "200/200 [==============================] - 0s 475us/step - loss: 4.2460 - val_loss: 21.1086\n",
      "Epoch 228/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 5.5513 - val_loss: 18.1902\n",
      "Epoch 229/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 6.6839 - val_loss: 18.8264\n",
      "Epoch 230/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 3.9805 - val_loss: 22.1844\n",
      "Epoch 231/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 7.5260 - val_loss: 18.0406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.9029 - val_loss: 18.1720\n",
      "Epoch 233/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 4.2700 - val_loss: 21.6723\n",
      "Epoch 234/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 7.0549 - val_loss: 18.3257\n",
      "Epoch 235/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.1116 - val_loss: 17.9955\n",
      "Epoch 236/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 4.8982 - val_loss: 19.8993\n",
      "Epoch 237/1000\n",
      "200/200 [==============================] - 0s 390us/step - loss: 5.5010 - val_loss: 18.2802\n",
      "Epoch 238/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 3.8601 - val_loss: 18.0206\n",
      "Epoch 239/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 4.4649 - val_loss: 19.8502\n",
      "Epoch 240/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 4.8163 - val_loss: 18.2233\n",
      "Epoch 241/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 3.8727 - val_loss: 18.0900\n",
      "Epoch 242/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 3.8981 - val_loss: 19.5267\n",
      "Epoch 243/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 4.5275 - val_loss: 18.0190\n",
      "Epoch 244/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.3243 - val_loss: 18.7832\n",
      "Epoch 245/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.6343 - val_loss: 19.4231\n",
      "Epoch 246/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.9891 - val_loss: 18.2600\n",
      "Epoch 247/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.7048 - val_loss: 19.3018\n",
      "Epoch 248/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.6605 - val_loss: 19.0433\n",
      "Epoch 249/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.4684 - val_loss: 18.2442\n",
      "Epoch 250/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.9499 - val_loss: 20.2273\n",
      "Epoch 251/1000\n",
      "200/200 [==============================] - 0s 405us/step - loss: 4.6394 - val_loss: 18.4078\n",
      "Epoch 252/1000\n",
      "200/200 [==============================] - 0s 410us/step - loss: 4.3387 - val_loss: 19.5309\n",
      "Epoch 253/1000\n",
      "200/200 [==============================] - 0s 395us/step - loss: 3.3752 - val_loss: 19.3007\n",
      "Epoch 254/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 3.1814 - val_loss: 18.7753\n",
      "Epoch 255/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 3.4483 - val_loss: 20.7341\n",
      "Epoch 256/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 4.5814 - val_loss: 18.4709\n",
      "Epoch 257/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 5.2030 - val_loss: 19.4963\n",
      "Epoch 258/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.1318 - val_loss: 20.7695\n",
      "Epoch 259/1000\n",
      "200/200 [==============================] - 0s 323us/step - loss: 4.4869 - val_loss: 18.4927\n",
      "Epoch 260/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 5.8538 - val_loss: 18.9358\n",
      "Epoch 261/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.2235 - val_loss: 23.7321\n",
      "Epoch 262/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 8.1163 - val_loss: 19.9576\n",
      "Epoch 263/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.4234 - val_loss: 19.1761\n",
      "Epoch 264/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 8.9190 - val_loss: 18.7431\n",
      "Epoch 265/1000\n",
      "200/200 [==============================] - 0s 375us/step - loss: 7.3314 - val_loss: 21.6006\n",
      "Epoch 266/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 6.1500 - val_loss: 21.8073\n",
      "Epoch 267/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 5.7569 - val_loss: 18.3132\n",
      "Epoch 268/1000\n",
      "200/200 [==============================] - 0s 415us/step - loss: 6.0346 - val_loss: 18.3464\n",
      "Epoch 269/1000\n",
      "200/200 [==============================] - 0s 415us/step - loss: 6.5245 - val_loss: 19.7482\n",
      "Epoch 270/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 3.8454 - val_loss: 20.5418\n",
      "Epoch 271/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 5.2685 - val_loss: 18.5151\n",
      "Epoch 272/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 3.9853 - val_loss: 18.2964\n",
      "Epoch 273/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 4.3649 - val_loss: 19.7946\n",
      "Epoch 274/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 3.9164 - val_loss: 19.5804\n",
      "Epoch 275/1000\n",
      "200/200 [==============================] - 0s 400us/step - loss: 3.6915 - val_loss: 18.1510\n",
      "Epoch 276/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 4.2723 - val_loss: 18.6447\n",
      "Epoch 277/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 3.1991 - val_loss: 20.0065\n",
      "Epoch 278/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.5759 - val_loss: 18.5280\n",
      "Epoch 279/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.2831 - val_loss: 18.4741\n",
      "Epoch 280/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 3.3846 - val_loss: 20.2235\n",
      "Epoch 281/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.9887 - val_loss: 18.6850\n",
      "Epoch 282/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.9888 - val_loss: 18.5170\n",
      "Epoch 283/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 3.1458 - val_loss: 20.0006\n",
      "Epoch 284/1000\n",
      "200/200 [==============================] - 0s 390us/step - loss: 3.7639 - val_loss: 18.7297\n",
      "Epoch 285/1000\n",
      "200/200 [==============================] - 0s 465us/step - loss: 3.3269 - val_loss: 19.3335\n",
      "Epoch 286/1000\n",
      "200/200 [==============================] - 0s 505us/step - loss: 2.8107 - val_loss: 19.6231\n",
      "Epoch 287/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.9626 - val_loss: 18.3458\n",
      "Epoch 288/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 3.8878 - val_loss: 19.8694\n",
      "Epoch 289/1000\n",
      "200/200 [==============================] - 0s 378us/step - loss: 3.1687 - val_loss: 19.0590\n",
      "Epoch 290/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.8164 - val_loss: 19.7096\n",
      "Epoch 291/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 2.6830 - val_loss: 19.1632\n",
      "Epoch 292/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.7157 - val_loss: 20.2155\n",
      "Epoch 293/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 3.0618 - val_loss: 18.7431\n",
      "Epoch 294/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.0708 - val_loss: 20.7662\n",
      "Epoch 295/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.1483 - val_loss: 19.3963\n",
      "Epoch 296/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.5807 - val_loss: 19.9384\n",
      "Epoch 297/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 2.6900 - val_loss: 19.2127\n",
      "Epoch 298/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.9675 - val_loss: 21.4585\n",
      "Epoch 299/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 4.0075 - val_loss: 18.9613\n",
      "Epoch 300/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.4580 - val_loss: 20.0673\n",
      "Epoch 301/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.5982 - val_loss: 19.3652\n",
      "Epoch 302/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.4353 - val_loss: 20.4938\n",
      "Epoch 303/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.8687 - val_loss: 18.9267\n",
      "Epoch 304/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.0775 - val_loss: 20.5563\n",
      "Epoch 305/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 2.8159 - val_loss: 19.3399\n",
      "Epoch 306/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.5034 - val_loss: 20.4975\n",
      "Epoch 307/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.7524 - val_loss: 18.8986\n",
      "Epoch 308/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 3.9212 - val_loss: 20.5824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "200/200 [==============================] - 0s 390us/step - loss: 2.8155 - val_loss: 19.3082\n",
      "Epoch 310/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 2.5195 - val_loss: 20.5695\n",
      "Epoch 311/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 2.9396 - val_loss: 18.8162\n",
      "Epoch 312/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.8527 - val_loss: 20.3567\n",
      "Epoch 313/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.5718 - val_loss: 19.4349\n",
      "Epoch 314/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.2173 - val_loss: 20.1103\n",
      "Epoch 315/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 2.3629 - val_loss: 19.0878\n",
      "Epoch 316/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.3330 - val_loss: 21.3943\n",
      "Epoch 317/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.5753 - val_loss: 19.2496\n",
      "Epoch 318/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 2.6807 - val_loss: 20.2842\n",
      "Epoch 319/1000\n",
      "200/200 [==============================] - 0s 440us/step - loss: 2.5882 - val_loss: 19.0675\n",
      "Epoch 320/1000\n",
      "200/200 [==============================] - 0s 405us/step - loss: 3.2023 - val_loss: 21.1607\n",
      "Epoch 321/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 3.2667 - val_loss: 19.2900\n",
      "Epoch 322/1000\n",
      "200/200 [==============================] - 0s 348us/step - loss: 2.7557 - val_loss: 20.5524\n",
      "Epoch 323/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.6101 - val_loss: 19.1202\n",
      "Epoch 324/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.1095 - val_loss: 21.0252\n",
      "Epoch 325/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.0245 - val_loss: 19.2391\n",
      "Epoch 326/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.8234 - val_loss: 20.6590\n",
      "Epoch 327/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.5947 - val_loss: 19.1040\n",
      "Epoch 328/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.0140 - val_loss: 20.8966\n",
      "Epoch 329/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.8779 - val_loss: 19.2460\n",
      "Epoch 330/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.8610 - val_loss: 20.7518\n",
      "Epoch 331/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.5750 - val_loss: 19.1733\n",
      "Epoch 332/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.8554 - val_loss: 20.8873\n",
      "Epoch 333/1000\n",
      "200/200 [==============================] - 0s 375us/step - loss: 2.8540 - val_loss: 19.2020\n",
      "Epoch 334/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.8600 - val_loss: 20.7871\n",
      "Epoch 335/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.5071 - val_loss: 19.2419\n",
      "Epoch 336/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.6524 - val_loss: 20.9294\n",
      "Epoch 337/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.9104 - val_loss: 19.1955\n",
      "Epoch 338/1000\n",
      "200/200 [==============================] - 0s 336us/step - loss: 2.9110 - val_loss: 20.7800\n",
      "Epoch 339/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 2.3727 - val_loss: 19.3457\n",
      "Epoch 340/1000\n",
      "200/200 [==============================] - 0s 415us/step - loss: 2.4449 - val_loss: 21.0224\n",
      "Epoch 341/1000\n",
      "200/200 [==============================] - 0s 405us/step - loss: 3.0150 - val_loss: 19.1730\n",
      "Epoch 342/1000\n",
      "200/200 [==============================] - 0s 400us/step - loss: 2.9791 - val_loss: 20.7137\n",
      "Epoch 343/1000\n",
      "200/200 [==============================] - 0s 390us/step - loss: 2.1866 - val_loss: 19.5296\n",
      "Epoch 344/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 2.1853 - val_loss: 21.1631\n",
      "Epoch 345/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 3.0466 - val_loss: 19.1645\n",
      "Epoch 346/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 3.1879 - val_loss: 20.5907\n",
      "Epoch 347/1000\n",
      "200/200 [==============================] - 0s 415us/step - loss: 1.9721 - val_loss: 19.8323\n",
      "Epoch 348/1000\n",
      "200/200 [==============================] - 0s 400us/step - loss: 1.7849 - val_loss: 20.6550\n",
      "Epoch 349/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.1813 - val_loss: 19.0912\n",
      "Epoch 350/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.7571 - val_loss: 20.8267\n",
      "Epoch 351/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 2.0331 - val_loss: 20.0486\n",
      "Epoch 352/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.6787 - val_loss: 20.3004\n",
      "Epoch 353/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 1.6625 - val_loss: 20.0404\n",
      "Epoch 354/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.8945 - val_loss: 21.9238\n",
      "Epoch 355/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.3709 - val_loss: 19.2831\n",
      "Epoch 356/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.5868 - val_loss: 20.4695\n",
      "Epoch 357/1000\n",
      "200/200 [==============================] - 0s 375us/step - loss: 1.6067 - val_loss: 21.2402\n",
      "Epoch 358/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 2.2652 - val_loss: 19.0774\n",
      "Epoch 359/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.8197 - val_loss: 19.9672\n",
      "Epoch 360/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 1.8270 - val_loss: 25.3121\n",
      "Epoch 361/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 8.3053 - val_loss: 23.1343\n",
      "Epoch 362/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 5.0800 - val_loss: 18.6941\n",
      "Epoch 363/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 7.5239 - val_loss: 18.9897\n",
      "Epoch 364/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 9.5696 - val_loss: 18.7152\n",
      "Epoch 365/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 4.4516 - val_loss: 25.0013\n",
      "Epoch 366/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 8.7669 - val_loss: 26.0334\n",
      "Epoch 367/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 10.7880 - val_loss: 20.7394\n",
      "Epoch 368/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.0737 - val_loss: 19.2997\n",
      "Epoch 369/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 8.8588 - val_loss: 20.7770\n",
      "Epoch 370/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 12.4546 - val_loss: 19.1786\n",
      "Epoch 371/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 10.2430 - val_loss: 18.7192\n",
      "Epoch 372/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.9759 - val_loss: 25.5716\n",
      "Epoch 373/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 9.0739 - val_loss: 26.9775\n",
      "Epoch 374/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 11.9047 - val_loss: 22.7143\n",
      "Epoch 375/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 8.2248 - val_loss: 18.8055\n",
      "Epoch 376/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.7980 - val_loss: 19.4770\n",
      "Epoch 377/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 7.7401 - val_loss: 19.3991\n",
      "Epoch 378/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 8.0428 - val_loss: 18.5174\n",
      "Epoch 379/1000\n",
      "200/200 [==============================] - 0s 318us/step - loss: 4.9999 - val_loss: 21.3991\n",
      "Epoch 380/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 5.2224 - val_loss: 23.2719\n",
      "Epoch 381/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 7.0878 - val_loss: 21.4372\n",
      "Epoch 382/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 5.1961 - val_loss: 18.7067\n",
      "Epoch 383/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 4.0871 - val_loss: 18.5979\n",
      "Epoch 384/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 5.8370 - val_loss: 18.6488\n",
      "Epoch 385/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.9965 - val_loss: 19.2480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.6396 - val_loss: 20.3408\n",
      "Epoch 387/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 5.0199 - val_loss: 19.6696\n",
      "Epoch 388/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.1274 - val_loss: 18.2804\n",
      "Epoch 389/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 3.7043 - val_loss: 17.9758\n",
      "Epoch 390/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.4182 - val_loss: 18.2645\n",
      "Epoch 391/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.1944 - val_loss: 19.6669\n",
      "Epoch 392/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.0318 - val_loss: 19.3400\n",
      "Epoch 393/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.5535 - val_loss: 17.9203\n",
      "Epoch 394/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.2652 - val_loss: 17.8936\n",
      "Epoch 395/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.4709 - val_loss: 18.9061\n",
      "Epoch 396/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.7438 - val_loss: 19.2993\n",
      "Epoch 397/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.0665 - val_loss: 18.3804\n",
      "Epoch 398/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 2.5728 - val_loss: 18.4178\n",
      "Epoch 399/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 2.5163 - val_loss: 19.6226\n",
      "Epoch 400/1000\n",
      "200/200 [==============================] - 0s 375us/step - loss: 2.7769 - val_loss: 19.2324\n",
      "Epoch 401/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 2.1107 - val_loss: 18.7933\n",
      "Epoch 402/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 2.6412 - val_loss: 19.8265\n",
      "Epoch 403/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 2.3043 - val_loss: 19.3157\n",
      "Epoch 404/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.9366 - val_loss: 19.1633\n",
      "Epoch 405/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.1086 - val_loss: 20.3076\n",
      "Epoch 406/1000\n",
      "200/200 [==============================] - 0s 395us/step - loss: 2.5669 - val_loss: 19.2220\n",
      "Epoch 407/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 2.3691 - val_loss: 20.0042\n",
      "Epoch 408/1000\n",
      "200/200 [==============================] - 0s 375us/step - loss: 1.9177 - val_loss: 19.7947\n",
      "Epoch 409/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 1.7924 - val_loss: 19.8640\n",
      "Epoch 410/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 1.7717 - val_loss: 20.4345\n",
      "Epoch 411/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 1.9459 - val_loss: 19.4434\n",
      "Epoch 412/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.7034 - val_loss: 21.0433\n",
      "Epoch 413/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.5394 - val_loss: 19.7831\n",
      "Epoch 414/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.0962 - val_loss: 20.7376\n",
      "Epoch 415/1000\n",
      "200/200 [==============================] - 0s 319us/step - loss: 2.0010 - val_loss: 19.6101\n",
      "Epoch 416/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.4100 - val_loss: 21.0884\n",
      "Epoch 417/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.5794 - val_loss: 19.7285\n",
      "Epoch 418/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.2961 - val_loss: 20.8919\n",
      "Epoch 419/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 1.9856 - val_loss: 19.7177\n",
      "Epoch 420/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.1493 - val_loss: 20.9761\n",
      "Epoch 421/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.4491 - val_loss: 19.5399\n",
      "Epoch 422/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.3595 - val_loss: 20.6988\n",
      "Epoch 423/1000\n",
      "200/200 [==============================] - 0s 348us/step - loss: 1.9071 - val_loss: 19.6971\n",
      "Epoch 424/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 1.9873 - val_loss: 21.0002\n",
      "Epoch 425/1000\n",
      "200/200 [==============================] - 0s 430us/step - loss: 2.4050 - val_loss: 19.4678\n",
      "Epoch 426/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 2.4388 - val_loss: 20.5986\n",
      "Epoch 427/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.8309 - val_loss: 19.6967\n",
      "Epoch 428/1000\n",
      "200/200 [==============================] - 0s 328us/step - loss: 1.8193 - val_loss: 20.9851\n",
      "Epoch 429/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.3847 - val_loss: 19.4522\n",
      "Epoch 430/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.5737 - val_loss: 20.6674\n",
      "Epoch 431/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 1.6933 - val_loss: 19.9331\n",
      "Epoch 432/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 1.6023 - val_loss: 21.0178\n",
      "Epoch 433/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.1777 - val_loss: 19.4794\n",
      "Epoch 434/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 2.9757 - val_loss: 20.7179\n",
      "Epoch 435/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.5127 - val_loss: 20.4709\n",
      "Epoch 436/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 1.3970 - val_loss: 19.7810\n",
      "Epoch 437/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.2075 - val_loss: 21.9885\n",
      "Epoch 438/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.2945 - val_loss: 20.2984\n",
      "Epoch 439/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 1.5658 - val_loss: 20.4613\n",
      "Epoch 440/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.3357 - val_loss: 20.8971\n",
      "Epoch 441/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.5740 - val_loss: 19.6264\n",
      "Epoch 442/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 3.3596 - val_loss: 21.1831\n",
      "Epoch 443/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.5874 - val_loss: 20.5796\n",
      "Epoch 444/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 1.3519 - val_loss: 20.4852\n",
      "Epoch 445/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 1.3361 - val_loss: 21.8717\n",
      "Epoch 446/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.5246 - val_loss: 19.7302\n",
      "Epoch 447/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.2871 - val_loss: 20.6657\n",
      "Epoch 448/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 1.2351 - val_loss: 22.1604\n",
      "Epoch 449/1000\n",
      "200/200 [==============================] - 0s 328us/step - loss: 3.4523 - val_loss: 19.8271\n",
      "Epoch 450/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 2.6044 - val_loss: 20.7164\n",
      "Epoch 451/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 1.2537 - val_loss: 21.3045\n",
      "Epoch 452/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.0635 - val_loss: 19.3896\n",
      "Epoch 453/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 3.9796 - val_loss: 20.1900\n",
      "Epoch 454/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.5914 - val_loss: 24.3921\n",
      "Epoch 455/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 7.1715 - val_loss: 23.0684\n",
      "Epoch 456/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 5.2755 - val_loss: 19.0616\n",
      "Epoch 457/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 4.8226 - val_loss: 18.8467\n",
      "Epoch 458/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 6.1378 - val_loss: 19.8675\n",
      "Epoch 459/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.7169 - val_loss: 23.6492\n",
      "Epoch 460/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 6.9717 - val_loss: 22.4908\n",
      "Epoch 461/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 5.7791 - val_loss: 18.8072\n",
      "Epoch 462/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.1962 - val_loss: 18.5845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.4295 - val_loss: 19.8231\n",
      "Epoch 464/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 1.8353 - val_loss: 20.7597\n",
      "Epoch 465/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.2320 - val_loss: 19.0097\n",
      "Epoch 466/1000\n",
      "200/200 [==============================] - 0s 308us/step - loss: 2.0468 - val_loss: 18.9690\n",
      "Epoch 467/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.0897 - val_loss: 20.5241\n",
      "Epoch 468/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.8677 - val_loss: 19.5314\n",
      "Epoch 469/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 1.7416 - val_loss: 18.6811\n",
      "Epoch 470/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.8648 - val_loss: 19.6378\n",
      "Epoch 471/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.8022 - val_loss: 20.0316\n",
      "Epoch 472/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.8176 - val_loss: 19.0237\n",
      "Epoch 473/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 2.7707 - val_loss: 20.0266\n",
      "Epoch 474/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.5833 - val_loss: 20.6218\n",
      "Epoch 475/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.2995 - val_loss: 19.1248\n",
      "Epoch 476/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.7145 - val_loss: 19.9253\n",
      "Epoch 477/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.3849 - val_loss: 21.4988\n",
      "Epoch 478/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.9653 - val_loss: 19.7258\n",
      "Epoch 479/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.0669 - val_loss: 20.0423\n",
      "Epoch 480/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.2916 - val_loss: 20.9520\n",
      "Epoch 481/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.3377 - val_loss: 19.4893\n",
      "Epoch 482/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.8236 - val_loss: 20.5815\n",
      "Epoch 483/1000\n",
      "200/200 [==============================] - 0s 405us/step - loss: 1.3367 - val_loss: 21.1857\n",
      "Epoch 484/1000\n",
      "200/200 [==============================] - 0s 450us/step - loss: 2.3287 - val_loss: 19.3233\n",
      "Epoch 485/1000\n",
      "200/200 [==============================] - 0s 420us/step - loss: 3.3252 - val_loss: 20.0113\n",
      "Epoch 486/1000\n",
      "200/200 [==============================] - 0s 440us/step - loss: 1.4223 - val_loss: 23.7125\n",
      "Epoch 487/1000\n",
      "200/200 [==============================] - 0s 435us/step - loss: 5.6101 - val_loss: 22.4108\n",
      "Epoch 488/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 3.3485 - val_loss: 19.0345\n",
      "Epoch 489/1000\n",
      "200/200 [==============================] - 0s 395us/step - loss: 5.9805 - val_loss: 18.9611\n",
      "Epoch 490/1000\n",
      "200/200 [==============================] - 0s 420us/step - loss: 6.9371 - val_loss: 19.5821\n",
      "Epoch 491/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 1.8186 - val_loss: 25.0084\n",
      "Epoch 492/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 9.0602 - val_loss: 25.8158\n",
      "Epoch 493/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 10.1565 - val_loss: 21.3766\n",
      "Epoch 494/1000\n",
      "200/200 [==============================] - 0s 347us/step - loss: 3.8652 - val_loss: 19.0009\n",
      "Epoch 495/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 7.8291 - val_loss: 20.2248\n",
      "Epoch 496/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 11.4433 - val_loss: 19.1724\n",
      "Epoch 497/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 9.6972 - val_loss: 18.4755\n",
      "Epoch 498/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.6452 - val_loss: 24.2369\n",
      "Epoch 499/1000\n",
      "200/200 [==============================] - 0s 390us/step - loss: 7.9194 - val_loss: 26.9333\n",
      "Epoch 500/1000\n",
      "200/200 [==============================] - 0s 435us/step - loss: 11.5961 - val_loss: 24.2053\n",
      "Epoch 501/1000\n",
      "200/200 [==============================] - 0s 448us/step - loss: 8.9108 - val_loss: 19.3507\n",
      "Epoch 502/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 2.7992 - val_loss: 18.9521\n",
      "Epoch 503/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 7.4357 - val_loss: 20.1081\n",
      "Epoch 504/1000\n",
      "200/200 [==============================] - 0s 358us/step - loss: 10.1128 - val_loss: 19.2700\n",
      "Epoch 505/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 8.7286 - val_loss: 18.2668\n",
      "Epoch 506/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.3240 - val_loss: 22.0438\n",
      "Epoch 507/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 5.9509 - val_loss: 23.9692\n",
      "Epoch 508/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 8.3672 - val_loss: 22.7075\n",
      "Epoch 509/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 6.9312 - val_loss: 19.4400\n",
      "Epoch 510/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.4626 - val_loss: 18.2019\n",
      "Epoch 511/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 5.6246 - val_loss: 18.4985\n",
      "Epoch 512/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 7.0625 - val_loss: 18.2473\n",
      "Epoch 513/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 5.5931 - val_loss: 18.6819\n",
      "Epoch 514/1000\n",
      "200/200 [==============================] - 0s 344us/step - loss: 3.3154 - val_loss: 20.4557\n",
      "Epoch 515/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 5.3635 - val_loss: 20.6365\n",
      "Epoch 516/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 5.7338 - val_loss: 19.0489\n",
      "Epoch 517/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.5780 - val_loss: 18.0404\n",
      "Epoch 518/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.1651 - val_loss: 18.0533\n",
      "Epoch 519/1000\n",
      "200/200 [==============================] - 0s 343us/step - loss: 5.2638 - val_loss: 17.9613\n",
      "Epoch 520/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 3.8465 - val_loss: 19.2083\n",
      "Epoch 521/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 3.3771 - val_loss: 20.2128\n",
      "Epoch 522/1000\n",
      "200/200 [==============================] - 0s 358us/step - loss: 4.4685 - val_loss: 19.3049\n",
      "Epoch 523/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 3.1362 - val_loss: 18.0748\n",
      "Epoch 524/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 3.4681 - val_loss: 18.0074\n",
      "Epoch 525/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 3.9394 - val_loss: 18.4298\n",
      "Epoch 526/1000\n",
      "200/200 [==============================] - 0s 363us/step - loss: 2.4433 - val_loss: 19.6817\n",
      "Epoch 527/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 3.6647 - val_loss: 19.4102\n",
      "Epoch 528/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 3.0876 - val_loss: 18.2555\n",
      "Epoch 529/1000\n",
      "200/200 [==============================] - 0s 353us/step - loss: 2.7882 - val_loss: 18.2304\n",
      "Epoch 530/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.1145 - val_loss: 19.1140\n",
      "Epoch 531/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.1181 - val_loss: 19.5213\n",
      "Epoch 532/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.6300 - val_loss: 18.5509\n",
      "Epoch 533/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 1.9928 - val_loss: 18.5482\n",
      "Epoch 534/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.0390 - val_loss: 19.5389\n",
      "Epoch 535/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.3098 - val_loss: 19.1586\n",
      "Epoch 536/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 1.6180 - val_loss: 18.8155\n",
      "Epoch 537/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.2211 - val_loss: 19.7391\n",
      "Epoch 538/1000\n",
      "200/200 [==============================] - 0s 338us/step - loss: 1.8387 - val_loss: 19.4490\n",
      "Epoch 539/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.4881 - val_loss: 19.2794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 1.7258 - val_loss: 20.3439\n",
      "Epoch 541/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.1680 - val_loss: 19.4218\n",
      "Epoch 542/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 1.7237 - val_loss: 19.9245\n",
      "Epoch 543/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.4321 - val_loss: 19.8076\n",
      "Epoch 544/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 1.3590 - val_loss: 20.0639\n",
      "Epoch 545/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 1.3365 - val_loss: 19.8762\n",
      "Epoch 546/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.4019 - val_loss: 20.7466\n",
      "Epoch 547/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.9860 - val_loss: 19.6233\n",
      "Epoch 548/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.4597 - val_loss: 20.5246\n",
      "Epoch 549/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.3336 - val_loss: 20.3539\n",
      "Epoch 550/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.2204 - val_loss: 19.8859\n",
      "Epoch 551/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 1.7144 - val_loss: 21.4718\n",
      "Epoch 552/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.8387 - val_loss: 20.1301\n",
      "Epoch 553/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.3925 - val_loss: 20.3091\n",
      "Epoch 554/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.1530 - val_loss: 20.5516\n",
      "Epoch 555/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 1.2956 - val_loss: 19.7159\n",
      "Epoch 556/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.4972 - val_loss: 21.0908\n",
      "Epoch 557/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 1.7607 - val_loss: 20.1015\n",
      "Epoch 558/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 1.4101 - val_loss: 20.9669\n",
      "Epoch 559/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.8748 - val_loss: 19.7472\n",
      "Epoch 560/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 2.4022 - val_loss: 20.8170\n",
      "Epoch 561/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 1.3178 - val_loss: 20.2679\n",
      "Epoch 562/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.1612 - val_loss: 20.8689\n",
      "Epoch 563/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 1.5096 - val_loss: 19.7337\n",
      "Epoch 564/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.8477 - val_loss: 20.8441\n",
      "Epoch 565/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.1823 - val_loss: 21.0528\n",
      "Epoch 566/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.7680 - val_loss: 19.5330\n",
      "Epoch 567/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.2670 - val_loss: 20.3149\n",
      "Epoch 568/1000\n",
      "200/200 [==============================] - 0s 338us/step - loss: 1.2219 - val_loss: 23.5761\n",
      "Epoch 569/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 5.5717 - val_loss: 22.3955\n",
      "Epoch 570/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.7881 - val_loss: 19.2418\n",
      "Epoch 571/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.6676 - val_loss: 19.0733\n",
      "Epoch 572/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 5.6808 - val_loss: 19.9105\n",
      "Epoch 573/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 1.4122 - val_loss: 23.9286\n",
      "Epoch 574/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 7.0962 - val_loss: 23.8386\n",
      "Epoch 575/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 7.1680 - val_loss: 20.1306\n",
      "Epoch 576/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 1.4749 - val_loss: 19.0037\n",
      "Epoch 577/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 7.1416 - val_loss: 19.2189\n",
      "Epoch 578/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 8.5264 - val_loss: 18.5219\n",
      "Epoch 579/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.9089 - val_loss: 21.4869\n",
      "Epoch 580/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 4.1033 - val_loss: 23.2690\n",
      "Epoch 581/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 6.4321 - val_loss: 21.0870\n",
      "Epoch 582/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 3.3753 - val_loss: 18.3457\n",
      "Epoch 583/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.6581 - val_loss: 18.4145\n",
      "Epoch 584/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 6.4385 - val_loss: 18.3520\n",
      "Epoch 585/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.0407 - val_loss: 20.2326\n",
      "Epoch 586/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.4772 - val_loss: 21.0909\n",
      "Epoch 587/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 5.0979 - val_loss: 19.4891\n",
      "Epoch 588/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.6248 - val_loss: 18.1916\n",
      "Epoch 589/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.3796 - val_loss: 18.1470\n",
      "Epoch 590/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 5.3270 - val_loss: 18.3726\n",
      "Epoch 591/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.7907 - val_loss: 20.9712\n",
      "Epoch 592/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 4.4389 - val_loss: 21.6638\n",
      "Epoch 593/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 5.4565 - val_loss: 19.6099\n",
      "Epoch 594/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.5873 - val_loss: 18.0764\n",
      "Epoch 595/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 4.6327 - val_loss: 18.1978\n",
      "Epoch 596/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 5.8342 - val_loss: 18.2145\n",
      "Epoch 597/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.3746 - val_loss: 20.4749\n",
      "Epoch 598/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.8917 - val_loss: 21.4756\n",
      "Epoch 599/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 5.3108 - val_loss: 19.7835\n",
      "Epoch 600/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.7789 - val_loss: 18.1653\n",
      "Epoch 601/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 4.2303 - val_loss: 18.2138\n",
      "Epoch 602/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 5.4288 - val_loss: 18.2937\n",
      "Epoch 603/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.0328 - val_loss: 20.5343\n",
      "Epoch 604/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.0537 - val_loss: 21.3381\n",
      "Epoch 605/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 5.2437 - val_loss: 19.5794\n",
      "Epoch 606/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.4566 - val_loss: 18.2255\n",
      "Epoch 607/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.5770 - val_loss: 18.3215\n",
      "Epoch 608/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 5.7129 - val_loss: 18.2987\n",
      "Epoch 609/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 3.1446 - val_loss: 20.5685\n",
      "Epoch 610/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.0760 - val_loss: 21.4752\n",
      "Epoch 611/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 5.4766 - val_loss: 19.7035\n",
      "Epoch 612/1000\n",
      "200/200 [==============================] - 0s 313us/step - loss: 2.6912 - val_loss: 18.1733\n",
      "Epoch 613/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.4617 - val_loss: 18.2891\n",
      "Epoch 614/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 5.8695 - val_loss: 18.2432\n",
      "Epoch 615/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.4843 - val_loss: 20.3574\n",
      "Epoch 616/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.5983 - val_loss: 21.2785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 5.0614 - val_loss: 19.6363\n",
      "Epoch 618/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 2.5002 - val_loss: 18.2504\n",
      "Epoch 619/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.3160 - val_loss: 18.3358\n",
      "Epoch 620/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 5.4606 - val_loss: 18.3347\n",
      "Epoch 621/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.9385 - val_loss: 20.5607\n",
      "Epoch 622/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.1182 - val_loss: 21.4246\n",
      "Epoch 623/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 5.4167 - val_loss: 19.6930\n",
      "Epoch 624/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.6291 - val_loss: 18.1906\n",
      "Epoch 625/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 4.4000 - val_loss: 18.3093\n",
      "Epoch 626/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 5.8089 - val_loss: 18.2076\n",
      "Epoch 627/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.5084 - val_loss: 20.0913\n",
      "Epoch 628/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.4094 - val_loss: 21.0145\n",
      "Epoch 629/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.8804 - val_loss: 19.5325\n",
      "Epoch 630/1000\n",
      "200/200 [==============================] - 0s 328us/step - loss: 2.4842 - val_loss: 18.1934\n",
      "Epoch 631/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.1094 - val_loss: 18.2270\n",
      "Epoch 632/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 5.1721 - val_loss: 18.3406\n",
      "Epoch 633/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 2.7536 - val_loss: 20.6077\n",
      "Epoch 634/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.0676 - val_loss: 21.3570\n",
      "Epoch 635/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 5.2299 - val_loss: 19.5958\n",
      "Epoch 636/1000\n",
      "200/200 [==============================] - 0s 425us/step - loss: 2.4765 - val_loss: 18.1474\n",
      "Epoch 637/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.3824 - val_loss: 18.2568\n",
      "Epoch 638/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 5.6936 - val_loss: 18.1996\n",
      "Epoch 639/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.3810 - val_loss: 20.1441\n",
      "Epoch 640/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.4436 - val_loss: 21.0721\n",
      "Epoch 641/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 4.8952 - val_loss: 19.5963\n",
      "Epoch 642/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.5411 - val_loss: 18.1988\n",
      "Epoch 643/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.9873 - val_loss: 18.2296\n",
      "Epoch 644/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 5.1002 - val_loss: 18.3322\n",
      "Epoch 645/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.7919 - val_loss: 20.4949\n",
      "Epoch 646/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 3.8740 - val_loss: 21.2583\n",
      "Epoch 647/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 5.0248 - val_loss: 19.6094\n",
      "Epoch 648/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 2.4028 - val_loss: 18.2045\n",
      "Epoch 649/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.2450 - val_loss: 18.2866\n",
      "Epoch 650/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 5.4418 - val_loss: 18.3018\n",
      "Epoch 651/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.1229 - val_loss: 20.3059\n",
      "Epoch 652/1000\n",
      "200/200 [==============================] - 0s 321us/step - loss: 3.5992 - val_loss: 21.1716\n",
      "Epoch 653/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.9558 - val_loss: 19.6648\n",
      "Epoch 654/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.5201 - val_loss: 18.2730\n",
      "Epoch 655/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.0180 - val_loss: 18.3103\n",
      "Epoch 656/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 5.2039 - val_loss: 18.3741\n",
      "Epoch 657/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.9577 - val_loss: 20.4386\n",
      "Epoch 658/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.6323 - val_loss: 21.2379\n",
      "Epoch 659/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 4.8706 - val_loss: 19.6884\n",
      "Epoch 660/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 2.4039 - val_loss: 18.3050\n",
      "Epoch 661/1000\n",
      "200/200 [==============================] - 0s 385us/step - loss: 4.0702 - val_loss: 18.3648\n",
      "Epoch 662/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 5.2025 - val_loss: 18.4182\n",
      "Epoch 663/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 2.9143 - val_loss: 20.3967\n",
      "Epoch 664/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.6797 - val_loss: 21.1755\n",
      "Epoch 665/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 4.9329 - val_loss: 19.6409\n",
      "Epoch 666/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.4535 - val_loss: 18.2728\n",
      "Epoch 667/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.0398 - val_loss: 18.3022\n",
      "Epoch 668/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 5.2369 - val_loss: 18.3273\n",
      "Epoch 669/1000\n",
      "200/200 [==============================] - 0s 318us/step - loss: 3.0179 - val_loss: 20.3264\n",
      "Epoch 670/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.5048 - val_loss: 21.1498\n",
      "Epoch 671/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.7845 - val_loss: 19.6498\n",
      "Epoch 672/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.4145 - val_loss: 18.2391\n",
      "Epoch 673/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.9414 - val_loss: 18.2872\n",
      "Epoch 674/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 5.0502 - val_loss: 18.3841\n",
      "Epoch 675/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 2.8118 - val_loss: 20.3685\n",
      "Epoch 676/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.6615 - val_loss: 21.1251\n",
      "Epoch 677/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.8495 - val_loss: 19.6217\n",
      "Epoch 678/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.3802 - val_loss: 18.3123\n",
      "Epoch 679/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 4.0219 - val_loss: 18.3528\n",
      "Epoch 680/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 5.1864 - val_loss: 18.3862\n",
      "Epoch 681/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.9772 - val_loss: 20.3387\n",
      "Epoch 682/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.4761 - val_loss: 21.1405\n",
      "Epoch 683/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.7515 - val_loss: 19.6695\n",
      "Epoch 684/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 2.4144 - val_loss: 18.2920\n",
      "Epoch 685/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.8756 - val_loss: 18.3279\n",
      "Epoch 686/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.9923 - val_loss: 18.4003\n",
      "Epoch 687/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.7973 - val_loss: 20.3366\n",
      "Epoch 688/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 3.5836 - val_loss: 21.0847\n",
      "Epoch 689/1000\n",
      "200/200 [==============================] - 0s 343us/step - loss: 4.7592 - val_loss: 19.5946\n",
      "Epoch 690/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 2.3442 - val_loss: 18.2565\n",
      "Epoch 691/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.9521 - val_loss: 18.2939\n",
      "Epoch 692/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 5.0795 - val_loss: 18.3553\n",
      "Epoch 693/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.8874 - val_loss: 20.2891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.4841 - val_loss: 21.0603\n",
      "Epoch 695/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.7230 - val_loss: 19.6040\n",
      "Epoch 696/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.3864 - val_loss: 18.2704\n",
      "Epoch 697/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 3.8528 - val_loss: 18.3004\n",
      "Epoch 698/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 4.9748 - val_loss: 18.3658\n",
      "Epoch 699/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.8147 - val_loss: 20.2931\n",
      "Epoch 700/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 3.4905 - val_loss: 21.0607\n",
      "Epoch 701/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.6772 - val_loss: 19.6164\n",
      "Epoch 702/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 2.3295 - val_loss: 18.2948\n",
      "Epoch 703/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.8656 - val_loss: 18.3390\n",
      "Epoch 704/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 4.9619 - val_loss: 18.4070\n",
      "Epoch 705/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.7934 - val_loss: 20.2724\n",
      "Epoch 706/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.4918 - val_loss: 20.9892\n",
      "Epoch 707/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.6860 - val_loss: 19.5284\n",
      "Epoch 708/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.3474 - val_loss: 18.2231\n",
      "Epoch 709/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.8382 - val_loss: 18.2352\n",
      "Epoch 710/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 4.9562 - val_loss: 18.2798\n",
      "Epoch 711/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.8217 - val_loss: 20.2030\n",
      "Epoch 712/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.4172 - val_loss: 20.9830\n",
      "Epoch 713/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.6138 - val_loss: 19.5505\n",
      "Epoch 714/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.3199 - val_loss: 18.1999\n",
      "Epoch 715/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.7912 - val_loss: 18.2465\n",
      "Epoch 716/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 4.8689 - val_loss: 18.3488\n",
      "Epoch 717/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.7273 - val_loss: 20.2342\n",
      "Epoch 718/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 3.4779 - val_loss: 20.9606\n",
      "Epoch 719/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.6384 - val_loss: 19.5351\n",
      "Epoch 720/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.3067 - val_loss: 18.2644\n",
      "Epoch 721/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.8188 - val_loss: 18.2823\n",
      "Epoch 722/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.9253 - val_loss: 18.3398\n",
      "Epoch 723/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.8077 - val_loss: 20.2352\n",
      "Epoch 724/1000\n",
      "200/200 [==============================] - 0s 328us/step - loss: 3.3704 - val_loss: 21.0040\n",
      "Epoch 725/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.5689 - val_loss: 19.5999\n",
      "Epoch 726/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.3129 - val_loss: 18.2836\n",
      "Epoch 727/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.7317 - val_loss: 18.3224\n",
      "Epoch 728/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.8025 - val_loss: 18.4030\n",
      "Epoch 729/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 2.6900 - val_loss: 20.2304\n",
      "Epoch 730/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.4405 - val_loss: 20.9095\n",
      "Epoch 731/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.5802 - val_loss: 19.4511\n",
      "Epoch 732/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.2719 - val_loss: 18.1558\n",
      "Epoch 733/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.7831 - val_loss: 18.1617\n",
      "Epoch 734/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.8711 - val_loss: 18.2035\n",
      "Epoch 735/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.7666 - val_loss: 20.0614\n",
      "Epoch 736/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.3513 - val_loss: 20.8098\n",
      "Epoch 737/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.5383 - val_loss: 19.4093\n",
      "Epoch 738/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.2994 - val_loss: 18.1084\n",
      "Epoch 739/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 3.6937 - val_loss: 18.1521\n",
      "Epoch 740/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 4.7674 - val_loss: 18.2322\n",
      "Epoch 741/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.6843 - val_loss: 20.0567\n",
      "Epoch 742/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 3.3797 - val_loss: 20.7660\n",
      "Epoch 743/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.5161 - val_loss: 19.3665\n",
      "Epoch 744/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.2474 - val_loss: 18.1145\n",
      "Epoch 745/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 3.7312 - val_loss: 18.1387\n",
      "Epoch 746/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.7970 - val_loss: 18.1992\n",
      "Epoch 747/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.7061 - val_loss: 20.0520\n",
      "Epoch 748/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.3478 - val_loss: 20.7993\n",
      "Epoch 749/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.5112 - val_loss: 19.4181\n",
      "Epoch 750/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.2797 - val_loss: 18.1283\n",
      "Epoch 751/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 3.6679 - val_loss: 18.1618\n",
      "Epoch 752/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.7434 - val_loss: 18.2363\n",
      "Epoch 753/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.6822 - val_loss: 20.0429\n",
      "Epoch 754/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.3250 - val_loss: 20.7576\n",
      "Epoch 755/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 4.4634 - val_loss: 19.3846\n",
      "Epoch 756/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.2307 - val_loss: 18.1270\n",
      "Epoch 757/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.6792 - val_loss: 18.1500\n",
      "Epoch 758/1000\n",
      "200/200 [==============================] - 0s 333us/step - loss: 4.7309 - val_loss: 18.2234\n",
      "Epoch 759/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.6609 - val_loss: 20.0383\n",
      "Epoch 760/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 3.3278 - val_loss: 20.7450\n",
      "Epoch 761/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.4703 - val_loss: 19.3604\n",
      "Epoch 762/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.2506 - val_loss: 18.1056\n",
      "Epoch 763/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.6465 - val_loss: 18.1433\n",
      "Epoch 764/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.7131 - val_loss: 18.2209\n",
      "Epoch 765/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 2.6652 - val_loss: 20.0519\n",
      "Epoch 766/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 3.2887 - val_loss: 20.7933\n",
      "Epoch 767/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 4.4251 - val_loss: 19.4336\n",
      "Epoch 768/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.2205 - val_loss: 18.1364\n",
      "Epoch 769/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.6332 - val_loss: 18.1512\n",
      "Epoch 770/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.6782 - val_loss: 18.2476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 771/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.6266 - val_loss: 20.0731\n",
      "Epoch 772/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.3058 - val_loss: 20.7903\n",
      "Epoch 773/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.4332 - val_loss: 19.4301\n",
      "Epoch 774/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.2267 - val_loss: 18.1575\n",
      "Epoch 775/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.6195 - val_loss: 18.1749\n",
      "Epoch 776/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.6807 - val_loss: 18.2687\n",
      "Epoch 777/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.6538 - val_loss: 20.0876\n",
      "Epoch 778/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 3.2459 - val_loss: 20.8015\n",
      "Epoch 779/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.3796 - val_loss: 19.4422\n",
      "Epoch 780/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.2058 - val_loss: 18.1526\n",
      "Epoch 781/1000\n",
      "200/200 [==============================] - 0s 328us/step - loss: 3.5887 - val_loss: 18.1626\n",
      "Epoch 782/1000\n",
      "200/200 [==============================] - 0s 328us/step - loss: 4.6222 - val_loss: 18.2678\n",
      "Epoch 783/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.5918 - val_loss: 20.0971\n",
      "Epoch 784/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.2797 - val_loss: 20.8111\n",
      "Epoch 785/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.3903 - val_loss: 19.4519\n",
      "Epoch 786/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 2.2020 - val_loss: 18.1646\n",
      "Epoch 787/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 3.5889 - val_loss: 18.1771\n",
      "Epoch 788/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 4.6383 - val_loss: 18.2730\n",
      "Epoch 789/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.6216 - val_loss: 20.0783\n",
      "Epoch 790/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 3.2298 - val_loss: 20.7903\n",
      "Epoch 791/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 4.3546 - val_loss: 19.4451\n",
      "Epoch 792/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.1903 - val_loss: 18.1595\n",
      "Epoch 793/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 3.5658 - val_loss: 18.1669\n",
      "Epoch 794/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 4.5983 - val_loss: 18.2736\n",
      "Epoch 795/1000\n",
      "200/200 [==============================] - 0s 395us/step - loss: 2.5860 - val_loss: 20.0785\n",
      "Epoch 796/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 3.2331 - val_loss: 20.7809\n",
      "Epoch 797/1000\n",
      "200/200 [==============================] - 0s 375us/step - loss: 4.3434 - val_loss: 19.4399\n",
      "Epoch 798/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 2.1859 - val_loss: 18.1723\n",
      "Epoch 799/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 3.5463 - val_loss: 18.1837\n",
      "Epoch 800/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 4.5822 - val_loss: 18.2889\n",
      "Epoch 801/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 2.5827 - val_loss: 20.0939\n",
      "Epoch 802/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 3.2135 - val_loss: 20.8021\n",
      "Epoch 803/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 4.3214 - val_loss: 19.4646\n",
      "Epoch 804/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.1725 - val_loss: 18.1784\n",
      "Epoch 805/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 3.5326 - val_loss: 18.1846\n",
      "Epoch 806/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 4.5617 - val_loss: 18.2925\n",
      "Epoch 807/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 2.5679 - val_loss: 20.0775\n",
      "Epoch 808/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.2024 - val_loss: 20.7754\n",
      "Epoch 809/1000\n",
      "200/200 [==============================] - 0s 341us/step - loss: 4.3068 - val_loss: 19.4509\n",
      "Epoch 810/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.1681 - val_loss: 18.1953\n",
      "Epoch 811/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.5147 - val_loss: 18.2055\n",
      "Epoch 812/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.5439 - val_loss: 18.3053\n",
      "Epoch 813/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 2.5596 - val_loss: 20.0738\n",
      "Epoch 814/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 3.1850 - val_loss: 20.7606\n",
      "Epoch 815/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.2846 - val_loss: 19.4303\n",
      "Epoch 816/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 2.1514 - val_loss: 18.1673\n",
      "Epoch 817/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 3.5063 - val_loss: 18.1757\n",
      "Epoch 818/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 4.5302 - val_loss: 18.2801\n",
      "Epoch 819/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.5487 - val_loss: 20.0662\n",
      "Epoch 820/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 3.1745 - val_loss: 20.7741\n",
      "Epoch 821/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.2748 - val_loss: 19.4616\n",
      "Epoch 822/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 2.1515 - val_loss: 18.2021\n",
      "Epoch 823/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 3.4867 - val_loss: 18.2102\n",
      "Epoch 824/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 4.5131 - val_loss: 18.3170\n",
      "Epoch 825/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 2.5404 - val_loss: 20.0918\n",
      "Epoch 826/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 3.1595 - val_loss: 20.7862\n",
      "Epoch 827/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 4.2555 - val_loss: 19.4693\n",
      "Epoch 828/1000\n",
      "200/200 [==============================] - 0s 363us/step - loss: 2.1383 - val_loss: 18.1958\n",
      "Epoch 829/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 3.4754 - val_loss: 18.2026\n",
      "Epoch 830/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 4.4973 - val_loss: 18.3187\n",
      "Epoch 831/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 2.5325 - val_loss: 20.0909\n",
      "Epoch 832/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 3.1419 - val_loss: 20.7897\n",
      "Epoch 833/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 4.2372 - val_loss: 19.4936\n",
      "Epoch 834/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 2.1365 - val_loss: 18.2450\n",
      "Epoch 835/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 3.4520 - val_loss: 18.2499\n",
      "Epoch 836/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 4.4697 - val_loss: 18.3684\n",
      "Epoch 837/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.5138 - val_loss: 20.1467\n",
      "Epoch 838/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 3.1354 - val_loss: 20.8437\n",
      "Epoch 839/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 4.2199 - val_loss: 19.5438\n",
      "Epoch 840/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 2.1177 - val_loss: 18.2713\n",
      "Epoch 841/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 3.4494 - val_loss: 18.2751\n",
      "Epoch 842/1000\n",
      "200/200 [==============================] - 0s 365us/step - loss: 4.4633 - val_loss: 18.3976\n",
      "Epoch 843/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 2.5095 - val_loss: 20.1467\n",
      "Epoch 844/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 3.1219 - val_loss: 20.8338\n",
      "Epoch 845/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 4.2112 - val_loss: 19.5540\n",
      "Epoch 846/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 2.1214 - val_loss: 18.3192\n",
      "Epoch 847/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 3.4288 - val_loss: 18.3239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 4.4456 - val_loss: 18.4386\n",
      "Epoch 849/1000\n",
      "200/200 [==============================] - 0s 380us/step - loss: 2.5030 - val_loss: 20.1741\n",
      "Epoch 850/1000\n",
      "200/200 [==============================] - 0s 370us/step - loss: 3.1022 - val_loss: 20.8517\n",
      "Epoch 851/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 4.1854 - val_loss: 19.5719\n",
      "Epoch 852/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.1043 - val_loss: 18.3401\n",
      "Epoch 853/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.4173 - val_loss: 18.3400\n",
      "Epoch 854/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 4.4244 - val_loss: 18.4447\n",
      "Epoch 855/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.4852 - val_loss: 20.1660\n",
      "Epoch 856/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.0993 - val_loss: 20.8368\n",
      "Epoch 857/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.1787 - val_loss: 19.5408\n",
      "Epoch 858/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.1043 - val_loss: 18.2668\n",
      "Epoch 859/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.4008 - val_loss: 18.2482\n",
      "Epoch 860/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.4113 - val_loss: 18.3458\n",
      "Epoch 861/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.4828 - val_loss: 20.0642\n",
      "Epoch 862/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.0796 - val_loss: 20.7323\n",
      "Epoch 863/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.1560 - val_loss: 19.4445\n",
      "Epoch 864/1000\n",
      "200/200 [==============================] - 0s 333us/step - loss: 2.0871 - val_loss: 18.1976\n",
      "Epoch 865/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 3.3941 - val_loss: 18.1939\n",
      "Epoch 866/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 4.3976 - val_loss: 18.3019\n",
      "Epoch 867/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.4722 - val_loss: 20.0199\n",
      "Epoch 868/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.0696 - val_loss: 20.6919\n",
      "Epoch 869/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 4.1459 - val_loss: 19.4188\n",
      "Epoch 870/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.0881 - val_loss: 18.1932\n",
      "Epoch 871/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.3745 - val_loss: 18.1953\n",
      "Epoch 872/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 4.3791 - val_loss: 18.3013\n",
      "Epoch 873/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.4617 - val_loss: 20.0196\n",
      "Epoch 874/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.0582 - val_loss: 20.6978\n",
      "Epoch 875/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.1289 - val_loss: 19.4299\n",
      "Epoch 876/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.0752 - val_loss: 18.1920\n",
      "Epoch 877/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.3657 - val_loss: 18.1921\n",
      "Epoch 878/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 4.3665 - val_loss: 18.3024\n",
      "Epoch 879/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.4545 - val_loss: 20.0070\n",
      "Epoch 880/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.0447 - val_loss: 20.6828\n",
      "Epoch 881/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.1155 - val_loss: 19.4292\n",
      "Epoch 882/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.0731 - val_loss: 18.2093\n",
      "Epoch 883/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.3471 - val_loss: 18.2103\n",
      "Epoch 884/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.3466 - val_loss: 18.3230\n",
      "Epoch 885/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.4431 - val_loss: 20.0318\n",
      "Epoch 886/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.0334 - val_loss: 20.7044\n",
      "Epoch 887/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.0976 - val_loss: 19.4478\n",
      "Epoch 888/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.0583 - val_loss: 18.2175\n",
      "Epoch 889/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 3.3415 - val_loss: 18.2164\n",
      "Epoch 890/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 4.3366 - val_loss: 18.3359\n",
      "Epoch 891/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.4361 - val_loss: 20.0444\n",
      "Epoch 892/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.0221 - val_loss: 20.7209\n",
      "Epoch 893/1000\n",
      "200/200 [==============================] - 0s 333us/step - loss: 4.0877 - val_loss: 19.4753\n",
      "Epoch 894/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.0588 - val_loss: 18.2488\n",
      "Epoch 895/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 3.3226 - val_loss: 18.2470\n",
      "Epoch 896/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.3185 - val_loss: 18.3689\n",
      "Epoch 897/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.4261 - val_loss: 20.0753\n",
      "Epoch 898/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.0110 - val_loss: 20.7463\n",
      "Epoch 899/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 4.0710 - val_loss: 19.5016\n",
      "Epoch 900/1000\n",
      "200/200 [==============================] - 0s 328us/step - loss: 2.0446 - val_loss: 18.2695\n",
      "Epoch 901/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.3174 - val_loss: 18.2650\n",
      "Epoch 902/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.3098 - val_loss: 18.3916\n",
      "Epoch 903/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 2.4221 - val_loss: 20.0859\n",
      "Epoch 904/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.9956 - val_loss: 20.7527\n",
      "Epoch 905/1000\n",
      "200/200 [==============================] - 0s 360us/step - loss: 4.0573 - val_loss: 19.5203\n",
      "Epoch 906/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.0443 - val_loss: 18.3037\n",
      "Epoch 907/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.2968 - val_loss: 18.2991\n",
      "Epoch 908/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.2872 - val_loss: 18.4241\n",
      "Epoch 909/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 2.4053 - val_loss: 20.1167\n",
      "Epoch 910/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.9920 - val_loss: 20.7829\n",
      "Epoch 911/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.0459 - val_loss: 19.5538\n",
      "Epoch 912/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.0314 - val_loss: 18.3311\n",
      "Epoch 913/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 3.2946 - val_loss: 18.3262\n",
      "Epoch 914/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.2842 - val_loss: 18.4502\n",
      "Epoch 915/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 2.4066 - val_loss: 20.1142\n",
      "Epoch 916/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.9732 - val_loss: 20.7733\n",
      "Epoch 917/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.0313 - val_loss: 19.5623\n",
      "Epoch 918/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.0326 - val_loss: 18.3681\n",
      "Epoch 919/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 3.2709 - val_loss: 18.3627\n",
      "Epoch 920/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.2583 - val_loss: 18.4812\n",
      "Epoch 921/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.3908 - val_loss: 20.1405\n",
      "Epoch 922/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.9657 - val_loss: 20.7915\n",
      "Epoch 923/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.0138 - val_loss: 19.5743\n",
      "Epoch 924/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.0145 - val_loss: 18.3786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 925/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.2706 - val_loss: 18.3728\n",
      "Epoch 926/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 4.2531 - val_loss: 18.4848\n",
      "Epoch 927/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.3868 - val_loss: 20.1274\n",
      "Epoch 928/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.9549 - val_loss: 20.7756\n",
      "Epoch 929/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.0065 - val_loss: 19.5582\n",
      "Epoch 930/1000\n",
      "200/200 [==============================] - 0s 332us/step - loss: 2.0181 - val_loss: 18.3429\n",
      "Epoch 931/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.2508 - val_loss: 18.3229\n",
      "Epoch 932/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 4.2353 - val_loss: 18.4359\n",
      "Epoch 933/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.3766 - val_loss: 20.0942\n",
      "Epoch 934/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 2.9454 - val_loss: 20.7450\n",
      "Epoch 935/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.9911 - val_loss: 19.5252\n",
      "Epoch 936/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.0029 - val_loss: 18.3040\n",
      "Epoch 937/1000\n",
      "200/200 [==============================] - 0s 305us/step - loss: 3.2487 - val_loss: 18.2910\n",
      "Epoch 938/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.2304 - val_loss: 18.4142\n",
      "Epoch 939/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.3763 - val_loss: 20.0665\n",
      "Epoch 940/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.9282 - val_loss: 20.7158\n",
      "Epoch 941/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.9773 - val_loss: 19.5076\n",
      "Epoch 942/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.0040 - val_loss: 18.3070\n",
      "Epoch 943/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.2271 - val_loss: 18.2960\n",
      "Epoch 944/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 4.2059 - val_loss: 18.4203\n",
      "Epoch 945/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.3580 - val_loss: 20.0833\n",
      "Epoch 946/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.9259 - val_loss: 20.7386\n",
      "Epoch 947/1000\n",
      "200/200 [==============================] - 0s 323us/step - loss: 3.9660 - val_loss: 19.5326\n",
      "Epoch 948/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.9921 - val_loss: 18.3199\n",
      "Epoch 949/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.2228 - val_loss: 18.3114\n",
      "Epoch 950/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 4.2008 - val_loss: 18.4403\n",
      "Epoch 951/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.3580 - val_loss: 20.0850\n",
      "Epoch 952/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.9093 - val_loss: 20.7394\n",
      "Epoch 953/1000\n",
      "200/200 [==============================] - 0s 324us/step - loss: 3.9522 - val_loss: 19.5511\n",
      "Epoch 954/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 1.9902 - val_loss: 18.3572\n",
      "Epoch 955/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 3.2056 - val_loss: 18.3468\n",
      "Epoch 956/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.1810 - val_loss: 18.4751\n",
      "Epoch 957/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.3437 - val_loss: 20.1173\n",
      "Epoch 958/1000\n",
      "200/200 [==============================] - 0s 345us/step - loss: 2.9044 - val_loss: 20.7630\n",
      "Epoch 959/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.9405 - val_loss: 19.5730\n",
      "Epoch 960/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 1.9779 - val_loss: 18.3797\n",
      "Epoch 961/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.2031 - val_loss: 18.3706\n",
      "Epoch 962/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.1779 - val_loss: 18.4972\n",
      "Epoch 963/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 2.3456 - val_loss: 20.1179\n",
      "Epoch 964/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 2.8860 - val_loss: 20.7586\n",
      "Epoch 965/1000\n",
      "200/200 [==============================] - 0s 310us/step - loss: 3.9258 - val_loss: 19.5805\n",
      "Epoch 966/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 1.9771 - val_loss: 18.4083\n",
      "Epoch 967/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.1833 - val_loss: 18.3979\n",
      "Epoch 968/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.1545 - val_loss: 18.5138\n",
      "Epoch 969/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.3262 - val_loss: 20.1286\n",
      "Epoch 970/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.8873 - val_loss: 20.7692\n",
      "Epoch 971/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 3.9187 - val_loss: 19.5909\n",
      "Epoch 972/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 1.9667 - val_loss: 18.4055\n",
      "Epoch 973/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.1817 - val_loss: 18.3940\n",
      "Epoch 974/1000\n",
      "200/200 [==============================] - 0s 328us/step - loss: 4.1551 - val_loss: 18.5126\n",
      "Epoch 975/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.3336 - val_loss: 20.1101\n",
      "Epoch 976/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.8634 - val_loss: 20.7463\n",
      "Epoch 977/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 3.9000 - val_loss: 19.5800\n",
      "Epoch 978/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 1.9638 - val_loss: 18.4118\n",
      "Epoch 979/1000\n",
      "200/200 [==============================] - 0s 390us/step - loss: 3.1620 - val_loss: 18.3982\n",
      "Epoch 980/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 4.1288 - val_loss: 18.5184\n",
      "Epoch 981/1000\n",
      "200/200 [==============================] - 0s 350us/step - loss: 2.3108 - val_loss: 20.1265\n",
      "Epoch 982/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.8675 - val_loss: 20.7601\n",
      "Epoch 983/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 3.8945 - val_loss: 19.5879\n",
      "Epoch 984/1000\n",
      "200/200 [==============================] - 0s 329us/step - loss: 1.9537 - val_loss: 18.4115\n",
      "Epoch 985/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.1619 - val_loss: 18.4007\n",
      "Epoch 986/1000\n",
      "200/200 [==============================] - 0s 320us/step - loss: 4.1320 - val_loss: 18.5184\n",
      "Epoch 987/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.3192 - val_loss: 20.1056\n",
      "Epoch 988/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 2.8443 - val_loss: 20.7400\n",
      "Epoch 989/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.8778 - val_loss: 19.5833\n",
      "Epoch 990/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 1.9542 - val_loss: 18.4191\n",
      "Epoch 991/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 3.1387 - val_loss: 18.4048\n",
      "Epoch 992/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 4.1035 - val_loss: 18.5243\n",
      "Epoch 993/1000\n",
      "200/200 [==============================] - 0s 355us/step - loss: 2.2965 - val_loss: 20.1204\n",
      "Epoch 994/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 2.8470 - val_loss: 20.7525\n",
      "Epoch 995/1000\n",
      "200/200 [==============================] - 0s 330us/step - loss: 3.8692 - val_loss: 19.5915\n",
      "Epoch 996/1000\n",
      "200/200 [==============================] - 0s 340us/step - loss: 1.9403 - val_loss: 18.4203\n",
      "Epoch 997/1000\n",
      "200/200 [==============================] - 0s 325us/step - loss: 3.1411 - val_loss: 18.4082\n",
      "Epoch 998/1000\n",
      "200/200 [==============================] - 0s 305us/step - loss: 4.1069 - val_loss: 18.5276\n",
      "Epoch 999/1000\n",
      "200/200 [==============================] - 0s 315us/step - loss: 2.3048 - val_loss: 20.1048\n",
      "Epoch 1000/1000\n",
      "200/200 [==============================] - 0s 335us/step - loss: 2.8246 - val_loss: 20.7335\n"
     ]
    }
   ],
   "source": [
    "stacked_lstm_hist = stacked_lstm.fit(x_train, y_train,\n",
    "                       epochs = 1000,\n",
    "                       batch_size = 256,\n",
    "                       verbose = 1, \n",
    "                       validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss of 16.806177139282227 reached at epoch 261\n"
     ]
    }
   ],
   "source": [
    "plot_loss(stacked_lstm_hist, 'Stacked LSTM - Train & Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE : 8.59560309521233\n",
      "Test RMSE : 21.391073451674053\n"
     ]
    }
   ],
   "source": [
    "train_pred = stacked_lstm.predict(x_train)\n",
    "test_pred = stacked_lstm.predict(x_test)\n",
    "\n",
    "train_RMSE = mean_squared_error(y_train, train_pred) ** 0.5\n",
    "test_RMSE = mean_squared_error(y_test, test_pred) ** 0.5\n",
    "\n",
    "print('Train RMSE :', train_RMSE)\n",
    "print('Test RMSE :', test_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of 314 dataset : 12.29860038254354\n"
     ]
    }
   ],
   "source": [
    "yy = stacked_lstm.predict(x)\n",
    "result = mean_squared_error(y, yy) ** 0.5\n",
    "print(\"RMSE of 314 dataset :\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model architecture\n",
    "model_json = stacked_lstm.to_json()\n",
    "open('stacked_lstm_with_100iterations.json', 'w').write(model_json)\n",
    "\n",
    "# save model's learned weights\n",
    "stacked_lstm.save_weights('stacked_lstm_weights_with_100iterations.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 1)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = yy\n",
    "# interpolation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
